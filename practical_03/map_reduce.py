from seed_data import all_feeds
from divide_and_conquer import merge_k_feeds
from collections import defaultdict


# Ð†Ð¼Ñ–Ñ‚Ð°Ñ†Ñ–Ñ Mapper (ÐÐ³ÐµÐ½Ñ‚)
def mapper(agent_data):
    # ÐšÐ¾Ð¶ÐµÐ½ Ð°Ð³ÐµÐ½Ñ‚ Ð²Ð¸Ð´Ð°Ñ” Ð½Ð¾Ð²Ð¸Ð½Ð¸ Ð· ÐºÐ»ÑŽÑ‡ÐµÐ¼ 'Ð´Ð°Ñ‚Ð°'
    output = []
    for post in agent_data:
        key = post["timestamp"].date()
        output.append((key, post))
    return output


# Shuffle Ñ„Ð°Ð·Ð° - Ð³Ñ€ÑƒÐ¿ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð° ÐºÐ»ÑŽÑ‡Ð°Ð¼Ð¸
def shuffle(mapped_by_agent):
    # Ð¡Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ð³Ñ€ÑƒÐ¿ÑƒÑ”Ð¼Ð¾ Ð·Ð° ÐºÐ»ÑŽÑ‡Ð°Ð¼Ð¸, Ð·Ð±ÐµÑ€Ñ–Ð³Ð°ÑŽÑ‡Ð¸ Ð¾ÐºÑ€ÐµÐ¼Ñ– Ð¿Ð¾Ñ‚Ð¾ÐºÐ¸ Ð²Ñ–Ð´ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²
    temp_grouped = defaultdict(lambda: defaultdict(list))
    for agent_idx, agent_mapped in enumerate(mapped_by_agent):
        for key, value in agent_mapped:
            temp_grouped[key][agent_idx].append(value)

    # ÐžÐ´Ñ€Ð°Ð·Ñƒ Ð¿ÐµÑ€ÐµÑ‚Ð²Ð¾Ñ€ÑŽÑ”Ð¼Ð¾ Ð² list of lists (Ð²Ñ–Ð´ÑÐ¾Ñ€Ñ‚Ð¾Ð²Ð°Ð½Ð¸Ñ… Ð¿Ð¾Ñ‚Ð¾ÐºÑ–Ð²)
    grouped = {}
    for key, agents_data in temp_grouped.items():
        grouped[key] = [agents_data[idx] for idx in sorted(agents_data.keys())]

    return grouped


# Ð†Ð¼Ñ–Ñ‚Ð°Ñ†Ñ–Ñ Reducer
def reducer(key, lists_to_merge):
    # lists_to_merge - Ð¼Ð°ÑÐ¸Ð² Ð²Ñ–Ð´ÑÐ¾Ñ€Ñ‚Ð¾Ð²Ð°Ð½Ð¸Ñ… ÑÐ¿Ð¸ÑÐºÑ–Ð² Ð²Ñ–Ð´ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²
    return merge_k_feeds(lists_to_merge)


# MapReduce workflow
def map_reduce_pipeline(feeds):
    # 1. MAP: ÐºÐ¾Ð¶ÐµÐ½ Ð°Ð³ÐµÐ½Ñ‚ Ð³ÐµÐ½ÐµÑ€ÑƒÑ” Ð¿Ð°Ñ€Ð¸ (key, value)
    mapped_by_agent = []
    for agent_feed in feeds:
        mapped = mapper(agent_feed)
        mapped_by_agent.append(mapped)

    print(f"MAP Ñ„Ð°Ð·Ð°: {len(feeds)} Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð² Ð·Ð³ÐµÐ½ÐµÑ€ÑƒÐ²Ð°Ð»Ð¸ Ð¿Ð°Ñ€Ð¸ (key, value)")
    for agent_idx, agent_mapped in enumerate(mapped_by_agent):
        print(f"  ÐÐ³ÐµÐ½Ñ‚ {agent_idx}: {len(agent_mapped)} Ð¿Ð°Ñ€ (key, value)")

    # 2. SHUFFLE: Ð³Ñ€ÑƒÐ¿ÑƒÑ”Ð¼Ð¾ Ð·Ð° Ð´Ð°Ñ‚Ð°Ð¼Ð¸, Ð·Ð±ÐµÑ€Ñ–Ð³Ð°ÑŽÑ‡Ð¸ Ð¾ÐºÑ€ÐµÐ¼Ñ– Ð¿Ð¾Ñ‚Ð¾ÐºÐ¸ Ð²Ñ–Ð´ Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²
    grouped = shuffle(mapped_by_agent)
    print(f"SHUFFLE Ñ„Ð°Ð·Ð°: Ð·Ð³Ñ€ÑƒÐ¿Ð¾Ð²Ð°Ð½Ð¾ Ð² {len(grouped)} ÑƒÐ½Ñ–ÐºÐ°Ð»ÑŒÐ½Ð¸Ñ… Ð´Ð°Ñ‚")
    print(f"ÐšÐ»ÑŽÑ‡Ñ– Ð¿Ñ–ÑÐ»Ñ shuffle: {list(grouped.keys())}")
    for key in sorted(grouped.keys()):
        total_news = sum(len(feed) for feed in grouped[key])
        print(f"  Ð”Ð°Ñ‚Ð° {key}: {total_news} Ð½Ð¾Ð²Ð¸Ð½ Ð²Ñ–Ð´ {len(grouped[key])} Ð°Ð³ÐµÐ½Ñ‚Ñ–Ð²")

    # 3. REDUCE: Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾ merge_k_feeds Ð´Ð»Ñ ÐºÐ¾Ð¶Ð½Ð¾Ñ— Ð´Ð°Ñ‚Ð¸
    results = {}
    for key, feeds_to_merge in grouped.items():
        results[key] = reducer(key, feeds_to_merge)
        print(f"REDUCE Ñ„Ð°Ð·Ð°: Ð´Ð°Ñ‚Ð° {key} -> {len(feeds_to_merge)} Ð¿Ð¾Ñ‚Ð¾ÐºÑ–Ð² Ð¾Ð±'Ñ”Ð´Ð½Ð°Ð½Ð¾")

    return results


if __name__ == "__main__":
    print("=" * 60)
    print("MapReduce Pipeline Ð· merge_k_feeds")
    print("=" * 60)
    results = map_reduce_pipeline(all_feeds)

    for date, news_list in sorted(results.items()):
        print(f"\nðŸ“… Ð”Ð°Ñ‚Ð°: {date}")
        for news in news_list:
            print(
                f"  {news['timestamp'].strftime('%H:%M')} | {news['source']} | {news['category']}: {news['content']}"
            )
